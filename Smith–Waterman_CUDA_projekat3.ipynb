{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Proka01/Smith-Waterman-python-CUDA/blob/main/Smith%E2%80%93Waterman_CUDA_projekat3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5kVhizy6LxG",
        "outputId": "409181b9-ad34-44a4-c95f-f282044bef3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pycuda\n",
            "  Downloading pycuda-2022.2.2.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2\n",
            "  Downloading pytools-2022.1.14.tar.gz (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from pycuda) (1.4.4)\n",
            "Collecting mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.8/dist-packages (from pytools>=2011.2->pycuda) (2.6.2)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.8/dist-packages (from pytools>=2011.2->pycuda) (4.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from mako->pycuda) (2.0.1)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2022.2.2-cp38-cp38-linux_x86_64.whl size=646530 sha256=ba4a3d9e5e4edff73cb06f97f5bb9bc302af854ed8d987bb5480b427e95942f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/41/0d/7cecb04af969d283ebe4a69579a8b2baec0d010a1ac4159f7e\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2022.1.14-py2.py3-none-any.whl size=69870 sha256=5a6e3f67ee62a050287e797ed7edaacdc74d05251f084fb0072f575f9daa9e52\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/fc/a9/1e7e56fe02d7f58eaff555f22e79d4fc2d817012291254bae2\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.2.4 pycuda-2022.2.2 pytools-2022.1.14\n"
          ]
        }
      ],
      "source": [
        "!pip install pycuda"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FP-r09z7l9X",
        "outputId": "a71bc27d-33d6-47fe-93ea-fb6c7a652104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jan 12 08:09:25 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def cuda_alloc(*args):\n",
        "  return [cuda.mem_alloc(arg.nbytes) for arg in args]\n",
        "\n",
        "\n",
        "def to_cuda(*args):\n",
        "  cuda_ptrs = cuda_alloc(*args)\n",
        "  for dst, src in zip(cuda_ptrs, args):\n",
        "     cuda.memcpy_htod(dst, src)\n",
        "  return cuda_ptrs\n",
        "\n",
        "g1 = \"AGCGA\"\n",
        "g2 = \"ACGAA\"\n",
        "gene1 = g1.encode()\n",
        "gene2 = g2.encode()\n",
        "\n",
        "gridSize = len(gene1) + 1\n",
        "grid = np.zeros(shape=(gridSize,gridSize)).astype(dtype=np.int32)\n",
        "gap = 2\n",
        "miss = 1\n",
        "mtch = 1"
      ],
      "metadata": {
        "id": "IjicFyUQKxVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Zadatak 1 - paralelno izvrsavanje\n",
        "\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "mod = SourceModule(\"\"\"\n",
        "     __global__ void SmithWaterman(int *grid, char *geneRow, char *geneCol, int match, int miss, int gap, int n)\n",
        "     {\n",
        "       int tid = threadIdx.x + 1;   //thread id 1-indexed\n",
        "       int cnt = 1;             //counts num of cells that thread has processed (thread should procces n cells)\n",
        "\n",
        "       int start = 1;\n",
        "       int end = 2*(n-1);\n",
        "\n",
        "      for(int did = start; did < end; did++) // did => diagonal id\n",
        "      {\n",
        "        if(did >= tid && cnt < n)\n",
        "        {\n",
        "          char Ai = geneRow[cnt-1];\n",
        "          char Bi = geneCol[tid-1];\n",
        "\n",
        "          int left = grid[tid*n + cnt-1];       // grid[tid][did-1];\n",
        "          int up = grid[(tid-1)*n + cnt];       //grid[tid-1][did];\n",
        "          int top = grid[(tid-1)*n + cnt-1];    // grid[tid-1][cnt-1];\n",
        "\n",
        "          int score = (Ai == Bi) ? match : -1*miss;\n",
        "\n",
        "          int ans = 0;                          //answer for grid[tid][did]\n",
        "          if(top + score > ans) ans = top + score;\n",
        "          if(up - gap > ans) ans = up - gap;\n",
        "          if(left - gap > ans) ans = left - gap;\n",
        "\n",
        "          grid[tid*n + cnt] = ans;\n",
        "\n",
        "          cnt++;\n",
        "        }\n",
        "\n",
        "        __syncthreads();\n",
        "      }\n",
        "\n",
        "\n",
        "     }\n",
        "   \"\"\")"
      ],
      "metadata": {
        "id": "GzoMoEUS8Mof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# kopiranje Host TO Device\n",
        "grid_cuda = to_cuda(grid)[0]\n",
        "gene1_cuda = cuda.mem_alloc(len(gene1))\n",
        "cuda.memcpy_htod(gene1_cuda, gene1)\n",
        "gene2_cuda = cuda.mem_alloc(len(gene2))\n",
        "cuda.memcpy_htod(gene2_cuda, gene2)\n",
        "\n",
        "\n",
        "func = mod.get_function(\"SmithWaterman\")  # priprema kernela za izvrsavanje\n",
        "\n",
        "func(grid_cuda, gene1_cuda, gene2_cuda, np.int32(mtch), np.int32(miss), np.int32(gap),np.int32(gridSize),\n",
        "     block=(gridSize-1,1,1), grid=(1, 1, 1))  # izrvrsavanje kernela\n",
        "\n",
        "cuda.memcpy_dtoh(grid, grid_cuda)  # kopiranje Device TO Host\n",
        "\n",
        "print(\"SmithWaterman:\\n\", grid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqSpJBSdKWgP",
        "outputId": "5e54380d-b754-4ebc-8f46-7c63b46df116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SmithWaterman:\n",
            " [[0 0 0 0 0 0]\n",
            " [0 1 0 0 0 1]\n",
            " [0 0 0 1 0 0]\n",
            " [0 0 1 0 2 0]\n",
            " [0 1 0 0 0 3]\n",
            " [0 1 0 0 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drugi zadatak"
      ],
      "metadata": {
        "id": "xI2IVJ8CizgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mod = SourceModule(\"\"\"\n",
        "     __global__ void reduce(int *a, int *result){\n",
        "     \n",
        "       extern __shared__ float data[];\n",
        "       int idx = threadIdx.x;\n",
        "       \n",
        "       data[idx] = a[idx];\n",
        "       __syncthreads();\n",
        "       \n",
        "       for(unsigned int s=1; s < blockDim.x; s *= 2) { \n",
        "       \n",
        "          if (idx % (2*s) == 0  && data[idx+s]>data[idx]){\n",
        "            data[idx] = data[idx + s]; \n",
        "          }   \n",
        "          __syncthreads(); \n",
        "       }\n",
        "       \n",
        "       // write result for this block to global mem\n",
        "       if (idx == 0) result[0] = data[0];\n",
        "\n",
        "    }\n",
        "   \"\"\")\n",
        "\n",
        "\n",
        "reduce_func = mod.get_function(\"reduce\")\n",
        "a_cuda = to_cuda(grid)[0]\n",
        "\n",
        "result = np.zeros(1, dtype=np.int32)\n",
        "result_cuda = to_cuda(result)[0]\n",
        "\n",
        "length = gridSize*gridSize\n",
        "reduce_func(a_cuda, result_cuda, shared=grid.nbytes, \n",
        "                                      block=(length, 1, 1), \n",
        "                                      grid=(1, 1, 1))\n",
        "\n",
        "cuda.memcpy_dtoh(result, result_cuda)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNazkWtOi1Zp",
        "outputId": "87c4290e-a838-4983-97ba-03bbc4491a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Konstantna memorija"
      ],
      "metadata": {
        "id": "V2Jsj-oVmYPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mod = SourceModule(\"\"\"\n",
        "     __constant__  char geneRow[6];\n",
        "     __constant__  char geneCol[6];\n",
        "\n",
        "     __global__ void SmithWatermanCM(int *grid, int match, int miss, int gap, int n)\n",
        "     {\n",
        "       int tid = threadIdx.x + 1;   //thread id 1-indexed\n",
        "       int cnt = 1;             //counts num of cells that thread has processed (thread should procces n cells)\n",
        "\n",
        "       int start = 1;\n",
        "       int end = 2*(n-1);\n",
        "\n",
        "      for(int did = start; did < end; did++) // did => diagonal id\n",
        "      {\n",
        "        if(did >= tid && cnt < n)\n",
        "        {\n",
        "          char Ai = geneRow[cnt-1];\n",
        "          char Bi = geneCol[tid-1];\n",
        "\n",
        "          int left = grid[tid*n + cnt-1];       // grid[tid][did-1];\n",
        "          int up = grid[(tid-1)*n + cnt];       //grid[tid-1][did];\n",
        "          int top = grid[(tid-1)*n + cnt-1];    // grid[tid-1][cnt-1];\n",
        "\n",
        "          int score = (Ai == Bi) ? match : -1*miss;\n",
        "\n",
        "          int ans = 0;                          //answer for grid[tid][did]\n",
        "          if(top + score > ans) ans = top + score;\n",
        "          if(up - gap > ans) ans = up - gap;\n",
        "          if(left - gap > ans) ans = left - gap;\n",
        "\n",
        "          grid[tid*n + cnt] = ans;\n",
        "\n",
        "          cnt++;\n",
        "        }\n",
        "\n",
        "        __syncthreads();\n",
        "      }\n",
        "\n",
        "\n",
        "     }\n",
        "   \"\"\")\n",
        "\n",
        "constant_mem = mod.get_function(\"SmithWatermanCM\")\n",
        "\n",
        "geneRow_cuda = mod.get_global('geneRow')[0]\n",
        "geneCol_cuda = mod.get_global('geneCol')[0]\n",
        "\n",
        "cuda.memcpy_htod(geneRow_cuda, gene1)\n",
        "cuda.memcpy_htod(geneCol_cuda, gene2)\n",
        "\n",
        "gridCM = np.zeros(shape=(gridSize,gridSize)).astype(dtype=np.int32)\n",
        "constant_mem(grid_cuda, np.int32(mtch), np.int32(miss), np.int32(gap),np.int32(gridSize),\n",
        "     block=(gridSize-1,1,1), grid=(1, 1, 1))  # izrvrsavanje kernela\n",
        "\n",
        "cuda.memcpy_dtoh(gridCM, grid_cuda)  # kopiranje Device TO Host\n",
        "\n",
        "print(\"SmithWaterman CONTANT MEMORY:\\n\", gridCM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6o0Oiyemcmf",
        "outputId": "0d53f88f-c4b6-4003-e98d-1fe2d6ca2534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SmithWaterman CONTANT MEMORY:\n",
            " [[0 0 0 0 0 0]\n",
            " [0 1 0 0 0 1]\n",
            " [0 0 0 1 0 0]\n",
            " [0 0 1 0 2 0]\n",
            " [0 1 0 0 0 3]\n",
            " [0 1 0 0 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deljena memorija"
      ],
      "metadata": {
        "id": "CULOoHLQrshh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mod = SourceModule(\"\"\"\n",
        "\n",
        "     __global__ void SmithWatermanSharedMem(int *grid, char *geneRow, char *geneCol, int match, int miss, int gap, int n)\n",
        "     {\n",
        "       int tid = threadIdx.x + 1;   //thread id 1-indexed\n",
        "       int cnt = 1;             //counts num of cells that thread has processed (thread should procces n cells)\n",
        "\n",
        "       int start = 1;\n",
        "       int end = 2*(n-1);\n",
        "      __shared__  char geneRow_share[6];\n",
        "      __shared__  char geneCol_share[6];\n",
        "\n",
        "      geneRow_share[tid-1] = geneRow[tid-1];\n",
        "      geneCol_share[tid-1] = geneCol[tid-1];\n",
        "\n",
        "      __syncthreads();\n",
        "\n",
        "      for(int did = start; did < end; did++) // did => diagonal id\n",
        "      {\n",
        "        if(did >= tid && cnt < n)\n",
        "        {\n",
        "          char Ai = geneRow_share[cnt-1];\n",
        "          char Bi = geneCol_share[tid-1];\n",
        "\n",
        "          int left = grid[tid*n + cnt-1];       // grid[tid][did-1];\n",
        "          int up = grid[(tid-1)*n + cnt];       //grid[tid-1][did];\n",
        "          int top = grid[(tid-1)*n + cnt-1];    // grid[tid-1][cnt-1];\n",
        "\n",
        "          int score = (Ai == Bi) ? match : -1*miss;\n",
        "\n",
        "          int ans = 0;                          //answer for grid[tid][did]\n",
        "          if(top + score > ans) ans = top + score;\n",
        "          if(up - gap > ans) ans = up - gap;\n",
        "          if(left - gap > ans) ans = left - gap;\n",
        "\n",
        "          grid[tid*n + cnt] = ans;\n",
        "\n",
        "          cnt++;\n",
        "        }\n",
        "\n",
        "        __syncthreads();\n",
        "      }\n",
        "\n",
        "\n",
        "     }\n",
        "   \"\"\")\n",
        "\n",
        "shared_mem = mod.get_function(\"SmithWatermanSharedMem\")\n",
        "\n",
        "gene1_cuda = cuda.mem_alloc(len(gene1))\n",
        "cuda.memcpy_htod(gene1_cuda, gene1)\n",
        "gene2_cuda = cuda.mem_alloc(len(gene2))\n",
        "cuda.memcpy_htod(gene2_cuda, gene2)\n",
        "\n",
        "gridSM = np.zeros(shape=(gridSize,gridSize)).astype(dtype=np.int32)\n",
        "shared_mem(grid_cuda, gene1_cuda, gene2_cuda, np.int32(mtch), np.int32(miss), np.int32(gap),np.int32(gridSize),\n",
        "     block=(gridSize-1,1,1), grid=(1, 1, 1))  # izrvrsavanje kernela\n",
        "\n",
        "cuda.memcpy_dtoh(gridSM, grid_cuda)  # kopiranje Device TO Host\n",
        "\n",
        "print(\"SmithWaterman SHARED MEMORY:\\n\", gridSM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5phUSgurt8X",
        "outputId": "bdd41ac6-d338-4a5c-b302-37d5ead1fb4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SmithWaterman SHARED MEMORY:\n",
            " [[0 0 0 0 0 0]\n",
            " [0 1 0 0 0 1]\n",
            " [0 0 0 1 0 0]\n",
            " [0 0 1 0 2 0]\n",
            " [0 1 0 0 0 3]\n",
            " [0 1 0 0 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treci zadatak"
      ],
      "metadata": {
        "id": "cEqVQbY4Ukps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mod = SourceModule(\"\"\"\n",
        "     __device__  int visited[36] = {1};\n",
        "\n",
        "\n",
        "     __global__ void SmithWatermanGrid(int *grid, int *vis, char *geneRow, char *geneCol, int match, int miss, int gap, int n)\n",
        "     {\n",
        "       int tid = threadIdx.x + blockDim.x*blockIdx.x + 1;   //thread id 1-indexed\n",
        "       int cnt = 1;             //counts num of cells that thread has processed (thread should procces n cells)\n",
        "\n",
        "       int start = 1;\n",
        "       int end = 2*(n-1);\n",
        "\n",
        "       if(tid>=n)return;\n",
        "    \n",
        "      for(int did = start; did < end; did++) // did => diagonal id\n",
        "      {\n",
        "        if(did >= tid && cnt < n)\n",
        "        {\n",
        "          char Ai = geneRow[cnt-1];\n",
        "          char Bi = geneCol[tid-1];\n",
        "          visited[tid*n+cnt] = 0;\n",
        "\n",
        "          while(true) {\n",
        "            if( visited[tid*n + cnt-1]!=0 && visited[(tid-1)*n + cnt]!=0 && visited[(tid-1)*n + cnt-1]!=0)break;\n",
        "          }\n",
        "\n",
        "          int left = grid[tid*n + cnt-1];       // grid[tid][did-1];\n",
        "          int up = grid[(tid-1)*n + cnt];       //grid[tid-1][did];\n",
        "          int top = grid[(tid-1)*n + cnt-1];    // grid[tid-1][cnt-1];\n",
        "\n",
        "          int score = (Ai == Bi) ? match : -1*miss;\n",
        "\n",
        "          int ans = 0;                          //answer for grid[tid][did]\n",
        "          if(top + score > ans) ans = top + score;\n",
        "          if(up - gap > ans) ans = up - gap;\n",
        "          if(left - gap > ans) ans = left - gap;\n",
        "\n",
        "          //grid[tid*n + cnt] = ans;\n",
        "          atomicAdd(&grid[tid*n + cnt], ans);\n",
        "          //vis[tid*n + cnt] = 1;\n",
        "          atomicAdd(&visited[tid*n + cnt], 1);\n",
        "          //vis[tid*n+cnt] = tid;\n",
        "          cnt++;\n",
        "        }\n",
        "        __syncthreads();\n",
        "\n",
        "      }\n",
        "      //grid[tid] = tid*(-1);\n",
        "\n",
        "     }\n",
        "   \"\"\")\n",
        "\n",
        "\n",
        "\n",
        "visited = np.zeros(shape=(gridSize,gridSize)).astype(dtype=np.int32)\n",
        "for i in range(gridSize):\n",
        "  visited[i][0]=1\n",
        "  visited[0][i]=1\n",
        "\n",
        "\n",
        "visited_cuda = to_cuda(visited)[0]\n",
        "\n",
        "\n",
        "print(visited)\n",
        "\n",
        "swGrid = mod.get_function(\"SmithWatermanGrid\")  # priprema kernela za izvrsavanje\n",
        "gridSW = np.zeros(shape=(gridSize,gridSize)).astype(dtype=np.int32)\n",
        "gridSW_cuda = to_cuda(gridSW)[0]\n",
        "\n",
        "swGrid(gridSW_cuda, visited_cuda, gene1_cuda, gene2_cuda, np.int32(mtch), np.int32(miss), np.int32(gap), np.int32(gridSize),\n",
        "     block=(2,1,1), grid=(4, 1, 1))  # izrvrsavanje kernela\n",
        "\n",
        "cuda.memcpy_dtoh(gridSW, gridSW_cuda)  # kopiranje Device TO Host\n",
        "cuda.memcpy_dtoh(visited, visited_cuda)\n",
        "\n",
        "print(visited)\n",
        "\n",
        "print(\"SmithWatermanGRID:\\n\", gridSW)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PSLK5j4Umdh",
        "outputId": "af107c7c-863d-413a-9c33-f4a685dd8c84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: device_allocation in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 1 1 1]\n",
            " [1 0 0 0 0 0]\n",
            " [1 0 0 0 0 0]\n",
            " [1 0 0 0 0 0]\n",
            " [1 0 0 0 0 0]\n",
            " [1 0 0 0 0 0]]\n",
            "[[1 1 1 1 1 1]\n",
            " [1 0 0 0 0 0]\n",
            " [1 0 0 0 0 0]\n",
            " [1 0 0 0 0 0]\n",
            " [1 0 0 0 0 0]\n",
            " [1 0 0 0 0 0]]\n",
            "SmithWatermanGRID:\n",
            " [[0 0 0 0 0 0]\n",
            " [0 1 0 0 0 1]\n",
            " [0 0 0 1 0 0]\n",
            " [0 0 1 0 2 0]\n",
            " [0 1 0 0 0 3]\n",
            " [0 1 0 0 0 1]]\n"
          ]
        }
      ]
    }
  ]
}